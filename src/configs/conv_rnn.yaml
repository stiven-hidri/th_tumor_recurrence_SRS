dataset:
  name: name
model:
  name: conv_rnn
  epochs: 30
  batch_size: 32
  optimizer: adam
  scheduler: plateau
  #patience: 1
  learning_rate: 5e-5
  weight_decay: 1e-2
  rnn_type: gru2  #rnn, lstm, gru, gru2
  dropout: .5
  only_test: False

  lf: bce          #wbce, bce, fl
  alpha_fl: .7
  gamma_fl: 3
  pos_weight: 6
  augmentation_techniques: ['shear', 'flip', 'gaussian_noise', 'brightness']
  p_augmentation: .8
  p_augmentation_per_technique: .3
logger:
  log_dir: ./log
  experiment_name: train_conv_rnn
  version: 1
checkpoint:
  monitor: val_loss
  save_top_k: 3
  mode: min