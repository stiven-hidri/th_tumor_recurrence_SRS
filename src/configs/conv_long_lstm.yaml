dataset:
  name: name
model:
  name: conv_long_lstm
  epochs: 150
  batch_size: 2
  optimizer: adam
  scheduler: cosine
  rnn_type: none
  hidden_size: 32
  num_layers: 1
  learning_rate: 5e-5
  weight_decay: 1e-4
  dropout: .3
  only_test: False
  use_clinical_data: True
  lf: fl          #wbce, bce, fl
  alpha_fl: .92
  gamma_fl: 2
  pos_weight: .8
  augmentation_techniques: ['shear', 'flip', 'rotate']
  p_augmentation: .3
  p_augmentation_per_technique: .4
logger:
  log_dir: ./log
  experiment_name: conv_long_lstm_1_cd_gridsearch
  version: 0
checkpoint:
  monitor: val_loss
  save_top_k: 1
  mode: min