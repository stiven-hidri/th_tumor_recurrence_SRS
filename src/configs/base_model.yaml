dataset:
  name: name
model:
  name: base_model
  epochs: 150
  batch_size: 32
  optimizer: adam
  scheduler: plateau
  rnn_type: None
  hidden_size: 0
  num_layers: 0
  lr: 1e-4
  weight_decay: 1e-3
  dropout: .3
  only_test: False
  lf: fl          #wbce, bce, fl
  use_clinical_data: True
  alpha_fl: .1
  gamma_fl: 2
  pos_weight: .3
  augmentation_techniques: ['random_affine', 'shear', 'random_rotate', 'random_flip']
  p_augmentation: 1.
  depth_attention: 1.
logger:
  log_dir: ./log
  experiment_name: train_base_model
  version: 1
checkpoint:
  monitor: val_loss
  save_top_k: 1
  mode: min